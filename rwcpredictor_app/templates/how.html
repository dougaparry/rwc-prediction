{% extends 'base.html' %}

{% block content %}

<div class="container">
	<div class="page-header text-center">
  		<h1>How it works</h1>
	</div>
</div>

<div class="container">
	<div class="row">
		<div class="col-xs-6">
			<h4 class="text-center"><a href="#stats" class="btn btn-default btn-lg btn-block" id="stats" role="button">Statistics</a>
</div>

		<div class="col-xs-6">
			<h4 class="text-center"><a href="#doug" class="btn btn-default btn-lg btn-block" role="button">Web</a>
		</div>
				</div>

				<hr>
</div>


</div>

<div class="row">
	<div class="col-xs-12">

<div class="container arnu" id = "arnu">
	<div id="header">
	<h1 class="title">Predicting the future of the 2015 Rugby World Cup using Domino and R.</h1>
	<h4 class="author"><em>Arnu Pretorius</em></h4>
	<h4 class="date"><em>08 September 2015</em></h4>
	</div>


	<p>For the sake of brevity, not all the relevant data and code are displayed in this post but can rather be found <a href="https://github.com/arnupretorius/RWCPrediction" title="github rwcPrediction">here</a>.</p>
	<div id="introduction" class="section level1">
	<h1>Introduction</h1>
	<p>The Rugby World Cup (RWC) is here! With many fans around the world excited to see the action unfold over the next month and a half.</p>
	<p>If you’ve never heard of the sport, <a href="http://www.whatisrugby.com/rugby-basics/rubgy-overview/" title="What is rugby">whatisrugby.com</a> provides the following short description:</p>
	<blockquote>
	<p>Rugby is a free-flowing game that features a combination of strength, speed and strategy to move a ball into an opponents territory. Rugby is a full-contact sport yet players wear little-or no protective gear. Rugby evolved from football (i.e. soccer) and is often called the ‘game played in heaven’.</p>
	</blockquote>
	<p>(Definitely an entertaining sport to watch, but the “game played in heaven”? Probably still up for debate.)</p>
	<p>In this blog post I go through the steps I took to build a machine learning model using <a href="https://www.dominodatalab.com/" title="Domino">Domino</a> and <a href="https://www.r-project.org/" title="R">R</a> to try predict the outcome of each upcoming RWC match. Don’t feel like reading it all? Feel free to skip to what strikes your fancy:</p>
	<ul>
	<li>Part 1: <a href="#getting-the-data">Getting the data</a></li>
	<li>Part 2: <a href="#exploring-the-data">Exploring the data</a></li>
	<li>Part 3: <a href="#model-selection">Model selection</a></li>
	<li>Part 4: <a href="#automating-the-process-using-domino-scheduling">Automating the process using Domino scheduling</a></li>
	<li>Part 5: <a href="#using-domino-api-endpoints-for-prediction-requests">Using Domino API Endpoints for prediction requests</a></li>
	</ul>
	<p>Before I go through the specifics, I would just like to mention that the initial idea was to simply get some relevant rugby data from the web, train a model using the data collected and then make predictions. Pretty simple, so lets get started!</p>
	<div id="getting-the-data" class="section level2">
	<h2>Getting the data</h2>
	<p>As with many machine learning undertakings the first step was to collect the data. I found a good source of rugby data at <a href="http://www.rugbydata.com/" title="Rugbydata">rugbydata.com</a>. For each of the 20 teams in the RWC I collected some general historical team statistics and past matches stretching back to the beginning of 2013 (shown below for South Africa).</p>
	<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/getting.png" alt="getting the data" />
	</p>

	<p>Only the matches between teams that are actually going to compete in the tournament were kept. In addition, tied matches were discarded. The first reason for this is due to the fact that in rugby a tied match is a fairly rare occurrence. The second, is that I was more concerned with predicting a win or a loss, the outcomes most fans care about, rather than also being able to predict match ties.</p>
	<p>As another data source I collected the rankings of each team as well as their recent change in rank from <a href="http://wrr.live555.com/" title="rankings">this site</a> (shown below).</p>

	<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/world.png" alt="world rankings" />
	</p>
	<p>Finally, connected to team rankings are ranking points that I managed to find on a <a href="https://en.wikipedia.org/wiki/World_Rugby_Rankings" title="wiki">world rugby rankings</a> Wikipedia page.</p>
	<p>
			<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/wiki.png" alt="heatmap" />
	</p>

	<p>Since most of the data only reflect the current state of each team’s historical performance and rank, weights were computed based on the date of each match (matches are treated as observations) in an attempt to adjust the data to exhibit a more accurate reflection of the past. The entire data collection, cleaning and structuring was done with <a href="https://github.com/arnupretorius/RWCPrediction/blob/master/GetRWCData.R" title="getRWCData">code</a> written in R.</p>
	</div>
	<div id="exploring-the-data" class="section level2">
	<h2>Exploring the data</h2>
	<p>Now that the data was in the bag, it was time to go explore! As a quick overview of the data I looked at a <a href="http://www.r-bloggers.com/using-r-correlation-heatmap-take-2/" title="corr heat map">heat map of the correlation</a> between all the variables.</p>
	<pre class="r"><code># load data
	data &lt;- read.csv(&quot;RWCData.csv&quot;)

	# Correlation heat map of the training data
	library(ggplot2)
	library(reshape2)
	dataCor &lt;- cbind(as.numeric(data[,1]), as.numeric(data[,2]), as.numeric(data[,3]), data[,-c(1,2,3)])

	colnames(dataCor) &lt;- colnames(data)
	title &lt;- &quot;Rugby training data correlation heat map&quot;
	corp &lt;- qplot(x=Var1, y=Var2, data=melt(cor(dataCor, use=&quot;p&quot;)), fill=value, geom=&quot;tile&quot;) +
	      scale_fill_gradient2(limits=c(-1, 1))
	corp &lt;- corp + theme(axis.title.x=element_blank(), axis.text.x=element_blank()
	                     , axis.ticks=element_blank())
	corp &lt;- corp + ggtitle(title)
	corp</code></pre>
</div>
<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/heat.png" alt="wikiworld rankings" />
</p>

<p>A dark blue square indicates a strong positive correlation between two variables and a dark red square a strong negative correlation. As I sort of expected many of the variables seemed to be correlated with each other (such as the average points scored against a team at home and the number of games the team lost at home). Nevertheless, in the first column of the heat map I was able find the degree of correlation between all the variables (indexed by the rows) with the outcome of the match. The rank of the home and away team seemed to be fairly correlated with the match outcome when compared to the other variables. So I took a closer look.</p>

<pre class="r"><code>ggplot(data, aes(RankAway, RankHome, color=Outcome)) + geom_point() + geom_smooth()</code></pre>

<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/plot.png" alt="plot" />
</p>
<p>Since the <em>Outcome</em> variable was coded to indicate whether the home team won or lost, I could clearly see that more winning matches were associated with the higher ranked teams playing at home. (It was also interesting to see my lack of data on poorly ranked teams.)</p>
</div>
<div id="model-selection" class="section level2">
<h2>Model selection</h2>
<p>I started off by splitting the data into a training and test set using the <a href="http://topepo.github.io/caret/index.html" title="caret">classification and regression training (caret) package</a> in R. This is an extremely powerful and handy package capable of performing many machine learning tasks from data pre-processing and splitting to model training, tuning and variable selection.</p>
<pre class="r"><code># Load libraries
library(caret)
library(randomForest)

# split data
set.seed(123)
trainIndex &lt;- createDataPartition(data[,1], p = .7,
                                  list = FALSE,
                                  times = 1)
train &lt;- data[trainIndex,]
test  &lt;- data[-trainIndex,]</code></pre>
<p>Due to its general good performance, ease of training and amenability for parallel processing, like many others I chose the <a href="https://en.wikipedia.org/wiki/Random_forest" title="rf">Random Forest</a> (RF) classifier as a good place to start. A Random Forest for classification is an ensemble of <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="class trees">classification trees</a> each built using a bootstrap sample of the observations and only allowing a random subset of variables for selection at each node split. The final classification takes the form of a majority vote. For a great introduction to classification trees and Random Forests take a look at <a href="https://class.coursera.org/bigdataschool-001/wiki/Day_8" title="RF slides">these slide</a> by Thomas Fuchs. In addition, I also investigated the performance of <a href="https://www.google.co.za/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CCEQFjAAahUKEwiX5P3Zv_bHAhVD6RQKHXhQBhg&amp;url=http%3A%2F%2Fpeople.csail.mit.edu%2Fmenze%2Fpapers%2Fmenze_11_oblique.pdf&amp;usg=AFQjCNFp_luWSlWHAKcZ5FoGta_4WSZzKg&amp;sig2=h_oL4JqZyKAcopJTykMw-At" title="orf">Oblique Random Forests</a> (ORF).</p>
<p>Normally the classification trees used in Random Forests split the variable space using orthogonal (perpendicular to the variable axis) splits, whereas Oblique Random Forests use some linear combination of the variables for splitting. Oblique trees are better suited for splitting a space consisting of many correlated variables, therefore I thought the Oblique Random Forest might perform better on the rugby data. Furthermore, many different linear classifiers can be used to produce the linear combinations used for splitting. I ended up using <a href="https://en.wikipedia.org/wiki/Partial_least_squares_regression" title="PLS">Partial Least Squares</a> (PLS).</p>
<p>The tuning parameter associated with the Random Forest and Oblique Random Forest is the size of the subset of randomly selected variables used at each node split. The following code sets up a tuning grid consisting of several different sizes of this subset and specifies the method used to train the model, in this case 5-fold <a href="chrome-extension://oemmndcbldboiebfnladdacbdfmadadm/http://research.cs.tamu.edu/prism/lectures/iss/iss_l13.pdf" title="CV">cross-validation (CV)</a>.</p>
<pre class="r"><code># Train classifiers
library(doParallel)
cl &lt;- makeCluster(8)
registerDoParallel(cl)

# Model tuning grids
rfGrid &lt;-  expand.grid(mtry = c(1, 7, 10, 15, 20, 25, 30, 35, 40, 45, 50))

# Tune using 5-fold cross-validation
fitControl &lt;- trainControl(method = &quot;cv&quot;,
                           number = 5,
                           repeats = 1)</code></pre>
<p>To train the models I used the <em>train</em> function from the caret package with the <em>method</em> argument set to “rf” for Random Forests and “ORFpls” for Oblique Random Forest using PLS for node splits. Below is the code for a RF using 1000 trees (with extra code bits to store the time it took to train the model).</p>
<pre class="r"><code># Random Forests
start.time &lt;- Sys.time()
set.seed(1)
rf &lt;- train(x=train[,-1], y=train[,1], method=&quot;rf&quot;, ntree=1000,trControl=fitControl, tuneGrid=rfGrid, importance=TRUE)
end.time &lt;- Sys.time()
time.taken.rf &lt;- end.time - start.time</code></pre>


<table class="table">
    <thead>
      <tr>
        <th>Model</th>
        <th>Training time</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Random Forest</td>
        <td>8.58 secs</td>
      </tr>
      <tr>
        <td>Oblique RF pls</td>
        <td>26.19 mins</td>
      </tr>
    </tbody>
  </table>

<p>The training time was 8.58 seconds for the RF and 26.19 minutes for the ORF, meaning that the ORF took roughly 183 times longer to train! This is because at each split for ORF a PLS model is fitted instead of a less computationally intense orthogonal split used in RF. The plot below shows the CV accuracy of each model for a different subset size of randomly selected variables as well as standard deviation bounds.</p>

<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/plot2.png" alt="plot" />
</p>

<p>Both models seemed to prefer small subset sizes (for the RF 7 and ORF 10) with the ORF outperforming the RF when the subset sizes were optimal for each model. However, the accuracy computed in this way (only using the training data) is not a true reflection of the models ability to generalise to unseen data. So to get a better idea of the performance of the models I plotted an <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" title="ROC curve">ROC</a> curve.</p>

<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/roc.png" alt="roc curve" />
</p>

<p>RF and ORF both produce <a href="https://en.wikipedia.org/wiki/Posterior_probability" title="post probs">posterior (after the data has been taken into account) probabilities</a> for observations to belong to a certain class. In a binary case, such as whether a team is going to loose or win a match, a threshold can be set (say 0.5) and if the posterior probability is above this threshold we classify to the “win”&quot; class, otherwise if it is below the threshold we classify to the “loose” class. The ROC curve shows the <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" title="FPR/TPR">false positive rate</a> (fraction of matches a team wins incorrectly classified as a loss) and <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" title="FPR/TPR">true positive rate</a> (fraction of matches a team won correctly classified as a win) for a sequence of thresholds from 0 to 1. Simply put, the classifier with a corresponding ROC curve that most closely hugs the top left corner of the plot as it arcs from the bottom left to the top right is considered to have the highest predictive power. So the two models seemed to be fairly similar. It was interesting to note that if the threshold was simply set to zero, both models would’ve correctly predicted a team winning when they actually won around 40% of the time. Lastly, the hold out test set was used to obtain the test accuracy of each model, given below.</p>

<table class="table">
    <thead>
      <tr>
        <th>Model</th>
        <th>Test set accuracy</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Random Forest</td>
        <td>74.14%</td>
      </tr>
      <tr>
        <td>Oblique RF pls</td>
        <td>75.86%</td>
      </tr>
    </tbody>
  </table>

<p>The ORF outperformed the RF by roughly 1.7%.</p>
<p>So there it was, I had my model! Ready with my trained Oblique Random Forest at my side I was going to predict the future of the Rugby World Cup. But then I thought, wouldn’t it be really cool if I could find some way to do what I just did, but between each match incorporate the latest result from the tournament? In other words, collect the outcome of a match just after it took place, add it to my data, retrain the model and make a prediction for the next match with the new up to date model. On top of this, would it be possible to do it in some automated fashion? Then along came Domino!</p>
</div>
<div id="automating-the-process-using-domino-scheduling" class="section level2">
<h2>Automating the process using Domino scheduling</h2>
<p>I first heard of Domino from <a href="http://blog.dominodatalab.com/using-r-h2o-and-domino-for-a-kaggle-competition/" title="domBlog1">this</a> great blog post by <a href="http://www.jofaichow.co.uk/" title="jo">Jo-Fai Chow</a> which shows you how to use R, <a href="http://h2o.ai/" title="H2O">H2O</a> and Domino for a <a href="https://www.kaggle.com/" title="kaggle">Kaggle</a> competition. In a nutshell, Domino is an enterprise-grade platform that enables you to run, scale, share, and deploy analytical models. The post also includes a tutorial on how to get started with Domino, from getting up and running to running your first R program in the cloud! I would recommend this as a good place to start for anyone new to Domino. Alternatively, you can simply sign up <a href="https://app.dominodatalab.com/signup" title="signup">here</a> for a 14-day free trial and once your account has been created you can access a Tour page that will get you up and running in no time.</p>
<p>So the first thing I needed to do to automate the process of data collection and model retraining was to upload my R scripts. First, the script (<em>GetRWCData.R</em>) responsible for getting and cleaning the data which outputs a .csv file containing the new data. Second, I had to upload the script (<em>RWCPrediction.R</em>) used to train the model on the outputted data, saving the model as a .rda file.</p>

<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/domino1.png" alt="domino" />
</p>

<p>As a last minute decision I decided to use the RF instead of the ORF because of the RF having a much sorter training time but still being a close contender regarding performance. Therefore the model training script <em>RWCPrediction.R</em> contains the following code.</p>
<pre class="r"><code>### International Rugby world cup match prediction model ###

# load libraries
library(caret)
library(randomForest)

# load data
data &lt;- read.csv(&quot;RWCData.csv&quot;)
cols &lt;- 4:ncol(data)
data[,cols] = apply(data[,cols], 2, function(x) as.numeric(x))

# tune Grid
rfGrid &lt;-  expand.grid(mtry = c(1, 7, 10, 15, 20, 25, 30, 35, 40, 45, 50))

# Tune using 5-fold cross-validation
fitControl &lt;- trainControl(method = &quot;cv&quot;,
                           number = 5,
                           repeats = 1)

# train classifier
model &lt;- train(x=data[,-1], y=data[,1], method=&quot;rf&quot;, ntree=1000,trControl=fitControl, tuneGrid=rfGrid)

# save model
saveRDS(model, file = &quot;RWC_Prediction_Model.rda&quot;)</code></pre>
<p>Now to automate using Domino’s scheduling functionality! To do this I simply went to the schedule tab, inserted my script for getting the data as the <em>command to run</em>, set a recurring time and clicked <em>schedule</em>. (The following example is slightly simplified since I had to fine tune the schedule to run between each game and not just every day at a fixed time.)</p>

<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/automate.png" alt="domino" />
</p>

<p>After the data script had ran successfully, the model script can use the new data to retrain the model. So similarly, I inserted my script for training the model as the <em>command to run</em>, set the recurring time (an hour after the data had been collected) and clicked <em>schedule</em>. Note in this case I also ticked the <em>publish after complete</em> box which takes care of republishing the API (more about this later).</p>

<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/domino2.png" alt="domino" />
</p>

<p>As easy as that I had an automated pipeline for data collection, cleaning and model training! However, from the very beginning of this project I wasn’t working alone, so while I was getting data and building models a good friend of mine <a href="https://twitter.com/dougaparry" title="doug">Doug</a> was building a web app to display the predictions. Once the app was up and running, all we needed to do was to figure out how it could get the model predictions. Enter Domino API Endpoints.</p>
</div>
<div id="using-domino-api-endpoints-for-prediction-requests" class="section level2">
<h2>Using Domino API Endpoints for prediction requests</h2>
<p>Domino’s API Endpoints enables you to have requests sent to R functions that you have written and uploaded to your project. <a href="http://www.programmableweb.com/news/how-to-turn-your-predictive-models-apis-using-domino/how-to/2015/07/22?page=2" title="domapi">This</a> post from <a href="http://blog.revolutionanalytics.com/" title="revolution Analytics">ProgrammableWeb</a> (again by <a href="http://www.jofaichow.co.uk/" title="jo">Jo-Fai Chow</a>) and <a href="https://twitter.com/DominoDataLab" title="nick">Nick’s</a> <a href="http://blog.revolutionanalytics.com/2014/08/using-r-inside-the-enterprise-integration-with-existing-systems.html" title="nick post">post</a> on <a href="http://www.programmableweb.com/" title="programmable web">Revolution Analytics</a> was all I needed to turn my predictive model into an API. The first step was to write a <em>predict_match</em> function inside an R script (given below) which takes as arguments the two teams and returns a prediction as a character string.</p>
<pre class="r"><code>## Load Library
library(caret)
library(randomForest)

## Load Pre-trained model
model &lt;- readRDS(file = &quot;RWC_Prediction_Model.rda&quot;)

## Load predictors
teamStats &lt;- readRDS(file=&quot;teamStats.rda&quot;)
rank &lt;- readRDS(&quot;rank.rda&quot;)
rankScore &lt;- readRDS(&quot;rankScore.rda&quot;)
rankChange &lt;- readRDS(&quot;rankChange.rda&quot;)

## Create a function to take team name inputs
## and then return a prediction for the match
predict_match &lt;- function(homeTeam, awayTeam) {

    teams &lt;- c(&quot;Namibia&quot;, &quot;South Africa&quot;, &quot;Argentina&quot;, &quot;Canada&quot;, &quot;United States&quot;,
               &quot;Uruguay&quot;, &quot;Japan&quot;, &quot;England&quot;, &quot;France&quot;, &quot;Georgia&quot;, &quot;Ireland&quot;,
               &quot;Italy&quot;, &quot;Romania&quot;, &quot;Scotland&quot;, &quot;Wales&quot;, &quot;Australia&quot;,
               &quot;Fiji&quot;, &quot;New Zealand&quot;, &quot;Samoa&quot;, &quot;Tonga&quot;)

    homeIndex &lt;- which(teams == homeTeam)
    awayIndex &lt;- which(teams == awayTeam)

    homeTeamStats &lt;- c(teamStats[[homeIndex]], rank[homeIndex], rankScore[homeIndex], rankChange[homeIndex])
    awayTeamStats &lt;- c(teamStats[[awayIndex]], rank[awayIndex], rankScore[awayIndex], rankChange[awayIndex])

    levelsx &lt;- levels(factor(teams))
    levelsy &lt;- levels(factor(c(&quot;loose&quot;,&quot;win&quot;)))
    newCase &lt;- read.csv(&quot;newCase.csv&quot;)
    levels(newCase[,1]) &lt;- levelsy
    levels(newCase[,2]) &lt;- levelsx
    levels(newCase[,3]) &lt;- levelsx
    newCase[1,2] &lt;- homeTeam
    newCase[1,3] &lt;- awayTeam
    newCase[1,4:27] &lt;- homeTeamStats
    newCase[1,28:51] &lt;- awayTeamStats


    ## Use the model for prediction
    y_probs &lt;- predict(model, newCase, type=&quot;prob&quot;)

    ## Return the predicted class
    return(as.character(y_probs))

}</code></pre>
<p>The next step was to upload this script (in my case called <em>model_API.R</em>) to my Domino project.</p>

<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/domino3.png" alt="domino" />
</p>

<p>The final step was to publish the API (which is really easy with Domino). I simply had to navigate to the <em>API Endpoints</em> tab, enter the name of the R script containing the prediction function, enter the prediction functions name and hit the <em>publish</em> button!</p>

<p>
		<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/domino4.png" alt="domino" />
</p>

<p>It’s alive!! (Frankenstein voice)</p>
<p>So this is currently where the project is at. Now that all the necessary pieces of the puzzle are in place, on a daily basis the data is collected, the model retrain and prediction requests sent using some Python code very similar to the code given below.</p>
<pre class="r"><code>import unirest
import json
import yaml

homeTeam = 'South Africa'
awayTeam = 'New Zealand'

response = unirest.post(&quot;https://app.dominodatalab.com/v1/Arnu/rwcPrediction/endpoint&quot;,
    headers={
        &quot;X-Domino-Api-Key&quot;: &quot;MY_API_KEY&quot;,
        &quot;Content-Type&quot;: &quot;application/json&quot;
    },
    params=json.dumps({
        &quot;parameters&quot;: [homeTeam, awayTeam]
    })
)

## Extract information from response
response_data = yaml.load(response.raw_body)

## Print Result only
print &quot;Predicted:&quot;
print response_data['result']</code></pre>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>So there you have it.</p>
<p>In summary, using <a href="https://www.dominodatalab.com/" title="Domino">Domino</a> together with <a href="https://www.r-project.org/" title="R">R</a> I was able to:</p>
<ol style="list-style-type: decimal">
<li>Write scripts to collect relevant Rugby data, perform exploratory analysis and select an appropriate model.</li>
<li>Automate the data collection to happen on a daily basis as new match results become available.</li>
<li>Automate the model training to happen after the data collection on daily basis.</li>
<li>Use the API Endpoints to turn the trained models into APIs capable of receiving prediction requests.</li>
<li>Automate the republishing of the API by ticking the <em>publish after complete</em> box when scheduling the training of the prediction model.</li>
</ol>
<p>If you are interested in seeing the model in action and getting your own prediction for a match, feel free to visit the <a href="http://rwcpredictor.herokuapp.com/" title="app">web app</a>.</p>
<p>Finally, I would just like to thank <a href="https://twitter.com/DominoDataLab" title="nick">Nick</a> who suggested to me that I write this blog post. Maybe I will write a follow up post when the tournament is over when all the results are in. :)</p>
<p>Until next time, all the best.</p>
<p id="doug">Arnu</p>


</div>
</div>
</div><!-- container arnu -->

<div class="container doug">
	<div id="header">
	<h1 class="title">Building a web application to handle and display predictions for the 2015 Rugby World Cup</h1>
	<h4 class="author"><em>Doug Parry</em></h4>
	<h4 class="date"><em>17 September 2015</em></h4>
	</div>

	<div id="introduction" class="section level1">

	<h1>Introduction</h1>
	<p>The Rugby World Cup (RWC) is here! With many fans around the world excited to see the action unfold over the next month and a half.</p>
	<p>If you’ve never heard of the sport, <a href="http://www.whatisrugby.com/rugby-basics/rubgy-overview/" title="What is rugby">whatisrugby.com</a> provides the following short description:</p>
	<blockquote>
	<p>Rugby is a free-flowing game that features a combination of strength, speed and strategy to move a ball into an opponents territory. Rugby is a full-contact sport yet players wear little-or no protective gear.</p>
	</blockquote>
	<blockquote>
		<p>
			Rugby is often described as a hooligans game, played by gentlemen.
		</p>
	</blockquote>
	<p>In this blog post I intend to go through the steps I took to build the web application
		 	to handle and display our predictions for the 2015 rugby world cup. These predictions are arrived
			at using the machine learning model described in the statistics section of this page.
			The github repository for this model may be viewed
			 <a href="https://github.com/arnupretorius/RWCPrediction" title="github rwcPrediction">
				here</a>. Don’t feel like reading it all?
			 Feel free to skip to the sections you are most interested in.</p>
	<ul>
	<li>Part 1: <a href="#tech-stack">Technology Stack</a></li>
	<li>Part 2: <a href="#getting-the-predictions">Getting the predictions</a></li>
	<li>Part 3: <a href="#automation">Automating the process</a></li>
	<li>Part 4: <a href="#creating-page-structure">Creating the page structure</a></li>
	<li>Part 5: <a href="#displaying-the-predictions">Displaying the predictions</a></li>
	<li>Part 6: <a href="#extras">Extra Features</a></li>
	<li>Part 6: <a href="#conclusion">Conclusion</a></li>
	</ul>
</div><!--Introduction -->

<div id="tech-stack" class="section level2">
		<h2>Technology Stack</h2>

		<p>
			I chose to develop this web application using python and the <a href="https://www.djangoproject.com/">Django</a>
			web application framework because I am most familiar and experienced with
			development in those languages/frameworks. In addition to these technologies,
			the application was developed with Javascript, HTML5, CSS (with a bootstrap framework)
			and some jquery. <p>

			<p>Similarly, I chose to host the application on <a href="https://www.heroku.com/">Heroku</a> because
			it is well suited to the framework within which I am working as well as my familiarity with the platform and its general ease of use.
			In my experience, heroku is an awesome and simple to use platform as a service (PaaS), providing many helpful
			fucntionalities and add-ons - aiding the development process. For persistent storage I chose
			to go with <a href="https://aws.amazon.com/s3/">AWS S3</a> because it provides a bit more flexibility and works seamlessly with Heroku.</p>

			<p>
				Other technologies used for various reasons (to be explained) include:
			</p>
			<ul>
				<li>Beautiful Soup</li>
				<li>Boto</li>
				<li>Gunicorn</li>
				<li>pyYaml</li>
				<li>Unirest</li>
				<li>The Heroku scheduler add-on</li>
			</ul>

			<h3>Brief Summary</h3>
			<p>
				In brief: A machine learning model was created and run on Domino data labs, from this model an API was created. A web application was then created and hosted
				on Heroku. This web application runs a scheduler which calls the API, saving the output persistently to AWS S3. This was then called and displayed on the application using python, django, javascript and bootstrap.
			</p>
</div>

<div id="getting-the-predictions" class="section level2">
		<h2>Getting the predictions</h2>

		<p>
			As Arnu explained in the <em>Statistics post,</em> we have used a machine-learning based
			technique to generate predictions for each match-up in the rugby world cup. The computations for this
			model are conducted on the cloud computing service <a href="https://www.dominodatalab.com/">Domino</a>.
			On Domino we have created an API which recieves 2 teams as inputs and then returns the probabilities of winning for each of the teams
		</p>

		<p>
					<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/domino4.png" alt="domino" />
		</p>

		<p>
			In order to get the predictions from this API, the following function is employed.
			This function takes in two team names and sends them to the API using unirest.
			The response is then handled using yaml and returned for further use elsewhere.
		</p>

<pre class="python"><code>def receiveProbs(teamA, teamB):
		response = unirest.post("https://app.dominodatalab.com/v1/Arnu/rwcPrediction/endpoint",
		    headers={
		        "X-Domino-Api-Key": "MY_APLI_KEY",
		        "Content-Type": "application/json" },
		    params=json.dumps({
		        "parameters": [teamA, teamB]}))

		response_data = yaml.load(response.raw_body)
		probability = response_data['result']
		return probability</code></pre>

	<p>
		In order to provide the above function with the correct teams for each match up, all
		of the fixtures have to be gathered and cleaned. The following 2 functions handle these processes.
		The first function geData(url) sends a request to the provided url. It then uses BeautifulSoup to
		clean this response and select only the data that is needed, returning this data as a list when it is called.
		The second function calls geData(url) passing the url to the location for the RWC 2015 fixtures. The second part
		of this function is mostly concerned with cleaning up the data and ordering it in the correct way.
	</p>

<pre class="python"><code>def getData(url):
    r = unirest.get(url)
    data = BeautifulSoup(r.raw_body,"lxml")
    cells= data.find_all("td",{"class":"cellfirst"})
    return cells

def fixtures():
    url = "http://www.supersport.com/rugby/rugby-world-cup/fixtures"
    data = getData(url)

    fixtures = list()

    i = 0
    j = 1

    while i < len(data):
        if j <= 21 and data[i+1].text == "USA":
            data[i+1] = "United States"
            fixtures.append([j,data[i].text + '/09/15',data[i+5].text,data[i+1], data[i+3].text,data[i+4].text])
        elif j <= 21 and data[i+3].text == "USA":
            data[i+3] = "United States"
            fixtures.append([j,data[i].text + '/09/15',data[i+5].text,data[i+1].text, data[i+3],data[i+4].text])
        elif j <= 21 and data[i+1].text != "USA" and data[i+3].text != "USA":
            fixtures.append([j,data[i].text + '/09/15',data[i+5].text,data[i+1].text, data[i+3].text,data[i+4].text])
        elif j > 21 and data[i+1].text == "USA":
            data[i+1] = "United States"
            fixtures.append([j,data[i].text + '/09/15',data[i+5].text,data[i+1], data[i+3].text,data[i+4].text])
        elif j > 21 and data[i+3].text == "USA":
            data[i+3] = "United States"
            fixtures.append([j,data[i].text + '/09/15',data[i+5].text,data[i+1].text, data[i+3],data[i+4].text])
        elif j > 21 and data[i+1].text != "USA" and data[i+3].text != "USA":
            fixtures.append([j,data[i].text + '/09/15',data[i+5].text,data[i+1].text, data[i+3].text,data[i+4].text])

        j +=1
        i +=7
    return fixtures
</code></pre>

<p>Finally! Now we have the fixtures and all of the information for each game, now we can set about getting the probabilities.
	This process involves looping through the list of each fixtures and foreach element in this list calling the getProbabilities() function
	shown above. The probabilities recieved as a response are then append to the particular element. Following this, the fixture information with
	probabilities now needs to be stored in a more permanent way than a list. I chose to store this information in a CSV file because of the ease at which
	they can be created, edited and sent to different locations - as well as there small size. The following function was emplpoyed to write the list to a CSV.
</p>

<pre class="python"><code>def writeCSV(list):
    with open('predictions.csv','w') as csvfile:
        writer = csv.writer(csvfile, delimiter = ',')
        for item in list:
            writer.writerow(item)
</code></pre>

<p>
	The CSV file looks like this
</p>

<p>
			<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/csv.png" alt="csv file" />
</p>

<p>
	Following this, the newly created CSV file can be uploaded to the AWS S3 bucket for this application. In order to do this the tool boto has been used.
	Boto allows for really simple interaction with Amazon's services. In addition to this, by using boto and heroku, the interaction process with AWS S3 is simplified and painless.
	For security reasons, a new IAM was created with a unique ID and special_key just for this process. For security reasons, this information should never be stored
	progromatically. luckily, heroku allows one to store this information in a config file which is used to define the virtual environment. When boto communicates with AWS, it
	then just pulls these values from the heroku environment. Uploading the CSV file to the S3 bucket is conducted in teh function displayed below.
</p>

<pre class+"python"><code>def upload():
    s3 = boto3.resource('s3')

    data = open('predictions.csv', 'rb')
    s3.Bucket('rwcbucket').put_object(Key='predictions.csv', Body=data)
</code></pre>

</div>

<div id="automation" class="section level2">
		<h2>Automating the process</h2>

		<p>
			The process described above; getting the fixtures information, getting the probabilities for each fixture, creating the CSV and uploading to
			the AWS S3 bucket is run automatically, on a schedule once a day. This is done because the machine-learning model retrains itself following each
			game or when new information is available. By doing this, the probabilities displayed are fresh and take the most recent information into account.
			The Heroku scheduler add-on is used to run this python script at a set time each day.
		</p>

		<p>
					<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/scheduler.png" alt="heroku scheduler add-on" />
		</p>
</div>

<div id="creating-page-structure" class="section level2">
		<h2>Creating the page structure</h2>

		<p>
			The front-end structure of the web app is fairly simple with the django framework guiding the use of views to recieve the data and call
			a set of templates for each page in the application. For the home page, displaying all of the predictions, boto is used once again to call the CSV style stored on
			AWS S3 and feed this in to a list which is passed to the template as a dictionary value. Similarly the standard Django process of using URL handlers reading regular expressions
			handles all urls and calls the functions in the view.
		</p>

		<p>
			As with most django applications, a base file has been created which handles all of the neccessary head content and calls
			to the various scripts and static files required. The home page then extends this base page, slotting in when called.
			For simplicity's sake, the entire main page is constructed using a series of loops, generating the content.
			The bootstrap column layout has been employed to structure the content of the page. When all is said and done, this page comes to 4036 lines of code,
			generated by only 80 lines. This code can be seen below.
		</p>

		<p>
					<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/home1.png" alt="home template" />
					<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/home2.png" alt="home template" />
		</p>

		<p>
			This code generates a series of 'cards' looking like this, for each game.
		</p>

		<p>
					<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/homecard.png" alt="home card" />
		</p>

</div>

<div id="displaying-the-predictions" class="section level2">
		<h2>Displaying the predictions</h2>
		<p>
			As can be seen from the previous image, a button is displayed allowing users to see the prediction for the particular match-up.
			When this button is clicked, a javascript function is run, setting the bottom half of the 'card' to be visible, showing the prediction
			and the tweet button. The code calling this function, passing the game number, the names of the 2 teams and the probabilities for each team is displayed above.
			When this is called, the following javascript function runs. This function simply changes the chosen element's class names to a new one, without the hidden attribute.
		</p>
		<pre><code>function showPrediction(game, prob1, prob2, teamA, teamB){
		document.getElementById(game+"-1").className = "text-center";
		document.getElementById(game+"-2").className = "text-center";
		document.getElementById(game+"-3").className = "text-center";

		if (prob1 > prob2){
			  document.getElementById(game+teamA).style.color = "green";
			} else {
			  document.getElementById(game+teamB).style.color = "green";
			}
		}</code></pre>

		<p>
			Once this script has run, the 'card' then looks like this.
		</p>

		<p>
					<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/after.png" alt="home card" />
		</p>
</div>

<div id="extras" class="section level2">
		<h2>Extra Features</h2>

		<h3>Twitter integration</h3>

		<p>
			We decided that integrating the application with twitter would be a cool way to promote it and incentivise people to use the application.
			The following code was used to generate tweet buttons, dynamic for each game of the RWC. This code calls some javascript, necessary to run it properly.
			As can be seen, each tweet is perfectly tailored for each result. Our hope with this is that through leveraging twitter, we can gain some social media attention.
		</p>

		<p>
					<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/tweet1.png" alt="tweet" />
		</p>

		<p>
			Upon clicking the tweet button, the following screen is displayed.
		</p>

		<p>
					<img class="img img-responsive center-block" src="{{ STATIC_URL }}/static/how/tweet2.png" alt="tweet" />
		</p>

		<h3>Time-based scrolling</h3>

		<p>
			A further extra feature included in the application is the functionality to scroll to the next game. We thought this would be a good idea because there
			are so many games, making it difficult for people to scroll down and find the next game. The following javascript functions achieved this.
		</p>

		<pre><code>// Function to determine which game to scroll to
		// compares the current date to any of the upcoming ones,
		// scrolling to the next most likely game

		function determine(){
		  var currentTime = new Date();
		  var games = [];

		  var game1 = new Date('September 18, 2015 21:00:00');
		  games.push(game1);
		  var game2 = new Date('September 19, 2015 13:00:00');
		  games.push(game2);
		  var game3 = new Date('September 19, 2015 15:30:00');
		  games.push(game3);
		  var game4 = new Date('September 19, 2015 17:45:00');
		  games.push(game4);
		  var game5 = new Date('September 19, 2015 21:00:00');
		  games.push(game5);
		  var game6 = new Date('September 20, 2015 13:00:00');
		  games.push(game6);
		  var game7 = new Date('September 20, 2015 15:30:00');
		  games.push(game7);
		  var game8 = new Date('September 20, 2015 17:45:00');
		  games.push(game8);
		  var game9 = new Date('September 23, 2015 15:30:00');
		  games.push(game9);
		  var game10 = new Date('September 23, 2015 17:45:00');
		  games.push(game10);
		  var game11 = new Date('September 23, 2015 21:00:00');
		  games.push(game11);
		  var game12 = new Date('September 24, 2015 21:00:00');
		  games.push(game12);
		  var game13 = new Date('September 25, 2015 17:45:00');
		  games.push(game13);
		  var game14 = new Date('September 26, 2015 15:30:00');
		  games.push(game14);
		  var game15 = new Date('September 26, 2015 17:45:00');
		  games.push(game15);
		  var game16 = new Date('September 26, 2015 21:00:00');
		  games.push(game16);
		  var game17 = new Date('September 27, 2015 13:00:00');
		  games.push(game17);
		  var game18 = new Date('September 27, 2015 15:30:00');
		  games.push(game18);
		  var game19 = new Date('September 27, 2015 17:45:00');
		  games.push(game19);
		  var game20 = new Date('September 29, 2015 17:45:00');
		  games.push(game20);
		  var game21 = new Date('October 1, 2015 17:45:00');
		  games.push(game21);
		  var game22 = new Date('October 1, 2015 21:00:00');
		  games.push(game22);
		  var game23 = new Date('October 2, 2015 21:00:00');
		  games.push(game23);
		  var game24 = new Date('October 3, 2015 15:30:00');
		  games.push(game24);
		  var game25 = new Date('October 3, 2015 17:45:00');
		  games.push(game25);
		  var game26 = new Date('October 3, 2015 21:00:00');
		  games.push(game26);
		  var game27 = new Date('October 4, 2015 15:30:00');
		  games.push(game27);
		  var game28 = new Date('October 4, 2015 17:45:00');
		  games.push(game28);
		  var game29 = new Date('October 6, 2015 17:45:00');
		  games.push(game29);
		  var game30 = new Date('October 6, 2015 21:00:00');
		  games.push(game30);
		  var game31 = new Date('October 7, 2015 17:45:00');
		  games.push(game31);
		  var game32 = new Date('October 7, 2015 21:00:00');
		  games.push(game32);
		  var game33 = new Date('October 9, 2015 21:00:00');
		  games.push(game33);
		  var game34 = new Date('October 10, 2015 15:30:00');
		  games.push(game34);
		  var game35 = new Date('October 10, 2015 17:45:00');
		  games.push(game35);
		  var game36 = new Date('October 10, 2015 21:00:00');
		  games.push(game36);
		  var game37 = new Date('October 11, 2015 13:00:00');
		  games.push(game37);
		  var game38 = new Date('October 11, 2015 15:30:00');
		  games.push(game38);
		  var game39 = new Date('October 11, 2015 17:45:00');
		  games.push(game39);
		  var game40 = new Date('October 11, 2015 21:00:00');
		  games.push(game40);

		  var returnVar = 0;

		  for(i = 0; i < 40; i++){
		    if(currentTime.getTime() < games[i].getTime()){
		        returnVar = i+1;
		        break;
		    }
		  }
		  return returnVar;
		}

		// helper function to improve cross browser support when determining the
		// current position

		function currentYPosition() {
		    // Firefox, Chrome, Opera, Safari
		    if (self.pageYOffset) return self.pageYOffset;
		    // Internet Explorer 6 - standards mode
		    if (document.documentElement && document.documentElement.scrollTop)
		        return document.documentElement.scrollTop;
		    // Internet Explorer 6, 7 and 8
		    if (document.body.scrollTop) return document.body.scrollTop;
		    return 0;
		}

		//Function to determine the position of the destination element

		function elmYPosition(eID) {
		    var elm = document.getElementById(eID);
		    var y = elm.offsetTop;
		    var node = elm;
		    while (node.offsetParent && node.offsetParent != document.body) {
		        node = node.offsetParent;
		        y += node.offsetTop;
		    } return y;
		}

		//Function to do the scrolling

		function smoothScroll() {
		    var eID = determine() + "-show";
		    var startY = currentYPosition();
		    var stopY = elmYPosition(eID);
		    var distance = stopY > startY ? stopY - startY : startY - stopY;
		    if (distance < 100) {
		        scrollTo(0, stopY); return;
		    }
		    var speed = Math.round(distance / 100);
		    if (speed >= 20) speed = 20;
		    var step = Math.round(distance / 25);
		    var leapY = stopY > startY ? startY + step : startY - step;
		    var timer = 0;
		    if (stopY > startY) {
		        for ( var i=startY; i<stopY; i+=step ) {
		            setTimeout("window.scrollTo(0, "+leapY+")", timer * speed);
		            leapY += step; if (leapY > stopY) leapY = stopY; timer++;
		        } return;
		    }
		    for ( var i=startY; i>stopY; i-=step ) {
		        setTimeout("window.scrollTo(0, "+leapY+")", timer * speed);
		        leapY -= step; if (leapY < stopY) leapY = stopY; timer++;
		    }
		    return false;
		}</code></pre>

		<h3>Google Analytics</h3>

		<p>
			Finally, google analytics functionality was included so that we can learn about the users of the website.
		</p>
</div>

<div id="conclusion" class="section level2">
		<h2>Conclusion</h2>

		<p>
			Ok, so that was a lot to take in.
		</p>
		<p>
			In conclusion, we created a machine learning model, that generated predictions for games for the 2015 rugby world cup. This model was then called
			on a schedule with teh results being stored on AWS S3. these results were then called and displayed on a web app hosted on heroku.
		</p>

		<p>
			I hope you have enjoyed this write up, and enjoy using the RWC2015 predictor.
		</p>
		<p>
		Doug
		</p>
</div>
</div> <!--doug-->




</div> <!-- col -->
</div> <!-- row -->

<div class="container">
	<div class="row">
		<div class="col-xs-6">
			<h4 class="text-center"><a href="#stats" class="btn btn-default btn-lg btn-block" id="stats" role="button">Statistics</a>
</div>

		<div class="col-xs-6">
			<h4 class="text-center"><a href="#doug" class="btn btn-default btn-lg btn-block" role="button">Web</a>
		</div>
				</div>

				<hr>
</div>

{% endblock %}
